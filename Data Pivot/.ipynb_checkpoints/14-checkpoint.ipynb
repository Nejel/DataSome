{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "from tensorflow.contrib.tensor_forest.python import tensor_forest\n",
    "from tensorflow.python.ops import resources\n",
    "from tensorflow.feature_column import bucketized_column\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "tf.enable_eager_execution() #new\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the data\n",
    "\n",
    "\n",
    "data = pd.read_csv('AllFiredAreFiredRnD2.66.csv', sep=';', encoding='latin-1', low_memory=False)\n",
    "datatopivot = data[['EmplId', 'Y', 'M', 'TerminationFact']]\n",
    "pivoted = datatopivot.pivot_table(index = ['EmplId', 'Y'], \n",
    "                        columns='M', values='TerminationFact', fill_value=0.0)\n",
    "merged = pd.merge(data, pivoted, how='left', on='EmplId')\n",
    "result = merged.drop_duplicates(subset='EmplId', keep='first', inplace=False)\n",
    "\n",
    "csvname = '14tmp2.csv'\n",
    "result.to_csv(path_or_buf= csvname)\n",
    "data = result\n",
    "\n",
    "#csv at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #tf.data processing. Way 1 \n",
    "# # https://www.youtube.com/watch?v=oFFbKogYdfc\n",
    "\n",
    "# csvname = 'covtype3.csv'\n",
    "\n",
    "\n",
    "# defaults = [tf.int32] * 55\n",
    "# dataset = tf.contrib.data.CsvDataset([csvname],\n",
    "#                                      defaults)\n",
    "# #print(list(dataset.take(1)))\n",
    "\n",
    "\n",
    "# col_names = ['Elevation','Aspect','Slope',\n",
    "#              'Horizontal_Distance_To_Hydrology',\n",
    "#              'Vertical_Distance_To_Hydrology',\n",
    "#              'Horizontal_Distance_To_Roadways',\n",
    "#              'Hillshade_9am','Hillshade_Noon',\n",
    "#              'Hillshade_3pm',\n",
    "#              'Horizontal_Distance_To_Fire_Points',\n",
    "#              'Wilderness_Area1','Wilderness_Area2',\n",
    "#              'Wilderness_Area3','Wilderness_Area4',\n",
    "#              'Soil_Type1','Soil_Type2','Soil_Type3',\n",
    "#              'Soil_Type4','Soil_Type5','Soil_Type6',\n",
    "#              'Soil_Type7','Soil_Type8','Soil_Type9',\n",
    "#              'Soil_Type10','Soil_Type11','Soil_Type12',\n",
    "#              'Soil_Type13','Soil_Type14','Soil_Type15',\n",
    "#              'Soil_Type16','Soil_Type17','Soil_Type18',\n",
    "#              'Soil_Type19','Soil_Type20','Soil_Type21',\n",
    "#              'Soil_Type22','Soil_Type23','Soil_Type24',\n",
    "#              'Soil_Type25','Soil_Type26','Soil_Type27',\n",
    "#              'Soil_Type28','Soil_Type29','Soil_Type30',\n",
    "#              'Soil_Type31','Soil_Type32','Soil_Type33',\n",
    "#              'Soil_Type34','Soil_Type35','Soil_Type36',\n",
    "#              'Soil_Type37','Soil_Type38','Soil_Type39',\n",
    "#              'Soil_Type40','Cover_Type']\n",
    "\n",
    "# def _parse_csv_row(*vals):\n",
    "#     soil_type_t = tf.convert_to_tensor(vals[14:54])\n",
    "#     feat_vals = vals[:10] + (soil_type_t, vals[54])\n",
    "#     features = dict(zip(col_names, feat_vals))\n",
    "    \n",
    "#     class_label = tf.argmax(row_vals[10:14], \n",
    "#                             axis = 0) #????\n",
    "    \n",
    "#     return features, class_label\n",
    "\n",
    "\n",
    "# dataset = dataset.map(_parse_csv_row).batch(64)\n",
    "\n",
    "# #.... To be continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.data processing. Way 2\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/experimental/CsvDataset\n",
    "\n",
    "dataset2 = tf.data.experimental.CsvDataset(\n",
    "    csvname,\n",
    "    [tf.float32,  # Required field, use dtype or empty tensor\n",
    "     tf.constant([0.0], dtype=tf.float32),  # Optional field, default to 0.0\n",
    "     tf.int32,  # Required field, use dtype or empty tensor\n",
    "     ],\n",
    "    #select_cols=[1,2,3]  # Only parse last three columns\n",
    ")\n",
    "\n",
    "#print(list(dataset.take(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{'Y': 'Y', 'M': 'M', 'EmplId': 'EmplId', 'FullNameEng': 'FullNameEng', 'Status': 'Status', 'VacationDaysCollected': 'VacationDaysCollected', 'TerminationFact': 'TerminationFact', 'Terminationdate': 'Terminationdate', 'TerminationReason': 'TerminationReason', 'Termreasoncategory': 'Termreasoncategory', 'TopDept': 'TopDept', 'DepFull': 'DepFull', 'StaffCountry': 'StaffCountry', 'Location': 'Location', 'HomeOffice': 'HomeOffice', 'StaffTypeName': 'StaffTypeName', 'HC': 'HC', 'Topdptreorg': 'Topdptreorg', 'Division': 'Division', 'Region': 'Region', 'Hiredate': 'Hiredate', 'LoS': 'LoS', 'DaysOfServ': 'DaysOfServ', 'DoB': 'DoB', 'Age': 'Age', 'Gender': 'Gender', 'Grade': 'Grade', 'Manager': 'Manager', 'SPAN': 'SPAN', 'Performance': 'Performance', 'Talent': 'Talent', 'CR': 'CR', 'Averageageintheteam': 'Averageageintheteam', 'AverageageintheteamDays': 'AverageageintheteamDays', 'Agediffwithteam1000': 'Agediffwithteam1000', 'numberofteammates': 'numberofteammates', 'Managersage': 'Managersage', 'AgediffwithManager': 'AgediffwithManager', 'Differentlocationwithmanager': 'Differentlocationwithmanager', 'Overtimehourscumul': 'Overtimehourscumul', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '10'}\n",
      "[_NumericColumn(key='Y', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='M', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='EmplId', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='FullNameEng', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Status', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='VacationDaysCollected', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='TerminationFact', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Terminationdate', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='TerminationReason', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Termreasoncategory', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='TopDept', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='DepFull', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='StaffCountry', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Location', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='HomeOffice', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='StaffTypeName', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='HC', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Topdptreorg', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Division', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Region', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Hiredate', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='LoS', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='DaysOfServ', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='DoB', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Gender', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Grade', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Manager', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='SPAN', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Performance', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Talent', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='CR', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Averageageintheteam', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='AverageageintheteamDays', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Agediffwithteam1000', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='numberofteammates', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Managersage', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='AgediffwithManager', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Differentlocationwithmanager', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='Overtimehourscumul', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='1', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='2', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='3', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='4', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='5', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='6', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='7', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='8', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='9', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000), _NumericColumn(key='10', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), (0, 2000)]\n"
     ]
    }
   ],
   "source": [
    "# feat_cols = [Y,M,EmplId,FullNameEng,Status,\n",
    "#              VacationDaysCollected,TerminationFact,\n",
    "#              Terminationdate,TerminationReason,\n",
    "#              Termreasoncategory,\n",
    "#              TopDept,DepFull,StaffCountry,Location,HomeOffice,\n",
    "#              StaffTypeName,HC,Topdptreorg,Division,Region,\n",
    "#              Hiredate,LoS,DaysOfServ,DoB,Age,Gender,Grade,\n",
    "#              Manager,SPAN,Performance,Talent,CR,\n",
    "#              Averageageintheteam,\n",
    "#              AverageageintheteamDays,Agediffwithteam1000,\n",
    "#              numberofteammates,Managersage,AgediffwithManager,\n",
    "#              Differentlocationwithmanager,Overtimehourscumul,\n",
    "#              1,2,3,4,5,6,7,8,9,10]\n",
    "d = {}\n",
    "x = []\n",
    "\n",
    "def addkey(key, number):\n",
    "    if key in d:\n",
    "        pass\n",
    "    else:\n",
    "        d[key] = str(key)\n",
    "\n",
    "        \n",
    "for i in data.columns:\n",
    "    addkey(i,0)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "for key in d:\n",
    "    tmpkey = str(key)\n",
    "    feat = tf.feature_column.numeric_column(tmpkey)\n",
    "    bucketized_feat = bucketized_column(feat, boundaries=[0,2000])\n",
    "    x.extend(bucketized_feat)\n",
    "\n",
    "#feat_cols.extend(key)   \n",
    "print(feat_cols)\n",
    "print(d)\n",
    "print(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [bucketized_Age,\n",
    "             bucketized_HomeOffice,bucketized_Location,\n",
    "             bucketized_HC,bucketized_Region,bucketized_Hiredate,\n",
    "             bucketized_LoS,bucketized_DoB,bucketized_Gender,\n",
    "             bucketized_Grade,bucketized_Manager,bucketized_SPAN,\n",
    "             bucketized_Performance,bucketized_Talent,bucketized_CR,\n",
    "             bucketized_numberofteammates,bucketized_Managerage,\n",
    "             bucketized_Differentlocationwithmanager,bucketized_StaffTypeName,\n",
    "             bucketized_Agediffwithteam,bucketized_AgediffwithManager,\n",
    "             bucketized_Averageage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training and eval\n",
    "# https://www.tensorflow.org/api_docs/python/tf/estimator/BoostedTreesClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = data\n",
    "labels = data['TerminationFact']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data,labels, test_size=0.5, random_state=101)\n",
    "##X_train2, X_test2, y_train2, y_test2 = train_test_split(x_data,labels, test_size=0.99, random_state=101)\n",
    "\n",
    "\n",
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=10,num_epochs=1000,shuffle=False)\n",
    "eval_input_func = tf.estimator.inputs.pandas_input_fn(x=X_test,y=y_test,batch_size=10,num_epochs=1,shuffle=False)\n",
    "\n",
    "model = tf.estimator.BoostedTreesClassifier(feature_columns=feat_cols, n_batches_per_layer=100,\n",
    "    n_trees = 15000, max_depth = 10, n_classes=2,\n",
    "    learning_rate = 0.1, l1_regularization = 0, l2_regularization = 0,\n",
    "    tree_complexity = 0, min_node_weight = 0)\n",
    "\n",
    "\n",
    "model.train(input_fn=input_func,steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results collecting and procesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
